---
title: "Samhouri et al tradeoff analysis run analysis"
author: "Jameal Samhouri"
date: "11/4/2020"
output: 
  html_document:
      toc: true
      toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This document runs the analysis included in the Samhouri et al. tradeoff manuscript.

See pseudocode in "Full workflow for risk assessment and tradeoff analysis" google doc. https://docs.google.com/document/d/1T8S5rEOACMCeGa5efS5BnEQY4gOw-PbxmvILJvShsQo/edit

1. MAKE SCENARIOS
2. RUN SCENARIOS
3. MAKE DF'S FOR TIME SERIES OF RISK, REVENUE, AND LANDINGS
4. CALCULATE SCENARIO RANKS
5. CALCULATE CHANGES IN RISK AND REVENUE BY PERIOD AND SCENARIO
+ repeat for statewide only and cenCA only scenarios
+ % change in each scenario's impact on risk and revenue between 2009-14 and 2014-18 periods
6. QUERY ENTANGLEMENT DATA
7. QUERY FISHING DATA
8. QUERY WHALE MODEL OUTPUTS
+ predicted occurrence/density by period, statewide and by region

* Fig 1 data. Whale and fishing data on 5km grid, averaged by time period
* Fig 2 data. Entanglement reports, DCRB revenue by crab year. whale risk is calculated in the scenario_analysis step
* Fig 3 data. Whale risk and DCRB revenue by scenario calculated in the scenario_analysis step
* Fig 4 data. Whale risk and DCRB revenue by scenario calculated in the scenario_analysis step

## Prep libraries and file paths
(no need to display messages)
```{r prep, include=FALSE}

# just getting libraries loaded and file paths sorted

library(tidyverse)
library(foreign) # read.dbf()
library(here)
library(lubridate)
library(sf)
library(viridis)
library(ggrepel)
library(magrittr)
library(ggerr)
library(scales)
library(maps)
library(rnaturalearth)
library(gridExtra)
library(ggpubr)
library(knitr)

source(here::here("User_script_local.R"))
if (user == "JS") {
  #flag.save = TRUE # option to save all outputs or not
  
  path_entanglement_file2 <- paste0(here::here(), "/tradeoffs/full_analysis_samhourietal/output_dfs/entanglement_df_annual_complete.csv")
  
  path_dcrb_vms_tix_analysis <- "~/Documents/RAIMBOW/Processed Data/VMS/vms_all_interpolated_w_grd_vlengths.RDS"
  
  path_dcrb_daily_all <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/VMS/CA_DCRB_vms_fishing_daily_2009-2019_all_vessels_regions_depths.RDS"
  
  path_season.st.date.key <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Input_Data/season_start_dates/start_dates_by_CA_region.rds"
  
  path_whales <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/5x5 Grid/Grid5km_whale.rds"
  
  path_Grid_5km_landerased <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/5x5 Grid/Grid_5km_landerased.RDATA"
  # 
  # path_figures <- "/Users/jameal.samhouri/Dropbox/Projects/In progress/RAIMBOW/raimbow/tradeoffs/Management scenarios/figures"
  # 
  # path_rds <- "/Users/jameal.samhouri/Dropbox/Projects/In progress/RAIMBOW/raimbow/tradeoffs/Management scenarios"
  # 
  # path_maps <- "/Users/jameal.samhouri/Dropbox/Projects/In progress/RAIMBOW/raimbow/tradeoffs/maps"
  # 
  # path_status_quo <- paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/scenario_output_dataframes/status_quo_risk_2009_2019_yr_mth_2020-06-14.rds") # from extract_status_quo_scenario_summary.R
  # 
  # path_status_quo_small_vessels <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/scenario_output_dataframes/status_quo_risk_small_vessels_2009_2019_yr_mth_2020-06-17.rds" # from extract_status_quo_scenario_summary_small.R 
  # 
  # 
  # path_Humpback_5km_long_monthly <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Input_Data/Humpback whale data/Forney et al./Humpback_5km_long_monthly.rds" 
  # 
  # path_BlueWhale_5km_long_monthly <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Input_Data/Blue whale data/Overlay on 5km Grid/BlueWhale_5km_long_monthly.rds"
  #   
  # path_effort_shift_scenariocomparisons_annual_statewide_df_n <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/annual_statewide_effort_shift_scenariocomparisons_n_2020-05-19.rds" # from effort_shift_comparison.R
  # 
  # path_tradeoff_df_effort_shift_scenariocomparisons_n <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/tradeoff_df_effort_shift_scenariocomparisons_n_2020-05-19.rds"
  # 
  # path_scenario_table_all <- "/Users/jameal.samhouri/Dropbox/Projects/In progress/RAIMBOW/raimbow/tradeoffs/Management scenarios/scenario_table_all_2020-06-09.rds"
  # 
  # path_scenario_table_focal_scenarios <- "/Users/jameal.samhouri/Dropbox/Projects/In progress/RAIMBOW/raimbow/tradeoffs/Management scenarios/scenario_table_focal_scenarios_2020-06-12.rds"
  # 
  # path_annual_statewide_df_focal_scenarios <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/annual_statewide_df_focal_scenarios_2020-06-12.rds" 
  # 
  # path_df_tradeoff_focal_scenarios <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/df_tradeoff_focal_scenarios_2020-06-12.rds" 
  # 
  # path_annual_statewide_df_focal_scenarios_small_vessels <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/annual_statewide_df_focal_scenarios_small_vessels_2020-06-16.rds"
  # 
  # path_df_tradeoff_focal_scenarios_small_vessels <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/df_tradeoff_focal_scenarios_small_vessels_2020-06-16.rds"
  # 
  # path_prioritizr_all <- "/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/prioritizr/prioritzr_outputs_all.rds"
  

} else if (user == "SMW") {
  NULL
} else {
  stop("Invalid user")
}


```


# 1. MAKE SCENARIOS
```{r make_scenarios, echo=FALSE}

source(paste0(here::here(), "/tradeoffs/Management scenarios/make_scenarios_table.R"))
# note season.st.key argument has to be defined separately from above

# scenario_table[1,]
# scenario_table_edr[1,]

# separate scenario tables need to be bound together.
# number the scenarios for easier reference. sq indicates status quo; redundant indicates scenario already represented and can be ignored; alt indicates scenario uses alt set of assumptions about what happens to effort (either remove or not removed and/or 10% v 100% of effort redistributed)
scenario_table_all <- scenario_table %>%
  bind_rows(scenario_table_edr) %>%
  mutate(
    scenario_number = c(
      "sq","1","2","3","6","8","4alt","7alt","9alt","5",
      "10","11","sq_redundant","1_redundant","2_redundant",
      "3_redundant","6_redundant","8_redundant","4","7","9",
      "5alt","10alt","11alt","12","13","14","15","16","17",
      "18","13alt","14alt","15alt","16alt","17alt","18alt"
    )
  )

# scenario_table_all[3,] == scenario_table_all[15,]

# convert factors to characters
scenario_table_all$delay_scenario <- as.character(scenario_table_all$delay_scenario)
scenario_table_all$delay_scenario <- as.character(scenario_table_all$delay_scenario)
scenario_table_all$closure_scenario <- as.character(scenario_table_all$closure_scenario)
scenario_table_all$closure_scenario <- as.character(scenario_table_all$closure_scenario)

glimpse(scenario_table_all)

write_csv(scenario_table_all,here::here(
  "tradeoffs",
  "Management scenarios",
  "scenario_table_all.csv"
          )
)

```

# 2. RUN SCENARIOS

## Loop through scenarios of interest and create a list of output df's
```{r run_scenarios1, echo=FALSE}

# note this chunk was adapted from scenario_analysis_all_vessels.R

### 1) Loop through scenarios of interest and create a list of output df's

# 1a) load function to shift fishing effort and daily fishing data
source(here::here(
  "tradeoffs",
  "Management scenarios",
  "Mgmt_scenarios_shift_effort.R")
)
x.orig <- read_rds(path_dcrb_daily_all)

# 1b) read in season start date key
# grab helper function. https://stackoverflow.com/questions/6364783/capitalize-the-first-letter-of-both-words-in-a-two-word-string
simpleCap <- function(x) {
  s <- sapply(strsplit(x, " "), function(i) i[[1]])
  paste(toupper(substring(s, 1, 1)), substring(s, 2),
        sep = "", collapse = " ")
}
season.st.date.key <- read_rds(path_season.st.date.key) %>% 
  mutate(crab_year = gsub("-", "_", .data$crab_season), 
         Region = unname(sapply(CA_region, simpleCap))) %>% 
  select(crab_year, Region, start_of_season_oneperc)

# 1c) shift effort for scenarios of interest

# drop redundant scenarios

scenario_table_all_trim <- scenario_table_all %>%
  filter(!grepl('redundant', scenario_number))

start.time <- Sys.time()

scenario.output.list <- lapply(1:nrow(scenario_table_all_trim), function(i, scenario_table_input) { # for testing. nrow(scenario_table_all_trim[1:2,])
  print(i)
  #browser()
  
  # i=1 # testing. no longer breaks because "At least one of delay.date or closure.date must not be NULL"
  # i=2 # testing. no longer breaks because when switch() is used and does not return NULL, it returns nothing
  
  scenario.output.df <- effort_mgmt(
    x = x.orig,
    
    season.st.key = season.st.date.key,
    
    preseason.days = scenario_table_all_trim$preseason.days[i],
    
    season.st.backstop = if (scenario_table_all_trim$season.st.backstop[i] == "NULL") {
      NULL
      }
    else {
      as.Date(scenario_table_all_trim$season.st.backstop[i])
      },
    
    early.data.method = scenario_table_all_trim$early.data.method[i], 
    
    delay.date = if (scenario_table_all_trim$delay.date[i] == "NULL") {
      NULL
    } else {
      as.Date(scenario_table_all_trim$delay.date[i])
    },
    
    delay.region = if (scenario_table_all_trim$delay.region[i] == "NULL") NULL else scenario_table_all_trim$delay.region[i],
    
    delay.method = if (scenario_table_all_trim$delay.method[i] == "NULL") NULL else scenario_table_all_trim$delay.method[i],
    
    delay.method.fidelity = scenario_table_all_trim$delay.method.fidelity[i],
    
    closure.date = if (scenario_table_all_trim$closure.date[i] == "NULL") NULL else as.Date(scenario_table_all_trim$closure.date[i]),
    
    closure.region = if (scenario_table_all_trim$closure.region[i] == "NULL") NULL else scenario_table_all_trim$closure.region[i],
    
    closure.method = if (scenario_table_all_trim$closure.method[i] == "NULL") NULL else scenario_table_all_trim$closure.method[i],
    
    closure.redist.percent = scenario_table_all_trim$closure.redist.percent[i],
    
    depth.shallow = if (scenario_table_all_trim$depth.shallow[i] == "NULL") NULL else as.numeric(scenario_table_all_trim$depth.shallow[i]), 
    
    depth.deep = if (scenario_table_all_trim$depth.deep[i] == "NULL") NULL else as.numeric(scenario_table_all_trim$depth.deep[i]),
    
    reduction.before.date = if (scenario_table_all_trim$reduction.before.date[i] == "NULL") NULL else scenario_table_all_trim$reduction.before.date[i],
    
    reduction.before.percent = 50,
    
    reduction.before.region = if (scenario_table_all_trim$reduction.before.region[i] == "NULL") NULL else scenario_table_all_trim$reduction.before.region[i],
    
    reduction.after.date = if (scenario_table_all_trim$reduction.after.date[i] == "NULL") NULL else as.Date(scenario_table_all_trim$reduction.after.date[i]),
    
    reduction.after.percent = 50,
    
    reduction.after.region = if (scenario_table_all_trim$reduction.after.region[i] == "NULL") NULL else scenario_table_all_trim$reduction.after.region[i],
    
    reduction.after.redist = if (scenario_table_all_trim$reduction.after.redist[i] == "FALSE") FALSE else TRUE,
    
    reduction.after.redist.percent = scenario_table_all_trim$reduction.after.redist.percent[i]
    
  )
  
}, scenario_table_input = scenario_table_all_trim)

Sys.time() - start.time

# JS. update directory as needed
save.image(paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/scenario_output_dataframes/scenario_output_",today(),".RData"))

```


## Calculate and summarize risk for multiple scenarios, including status quo
```{r run_scenarios2, echo=FALSE}

# note this chunk was adapted from scenario_analysis_all_vessels.R

### 2) Calculate and summarize risk for multiple scenarios, including status quo

# 2a) grab shifted effort fishing data if not running full code above
# JS. update directory as needed 
# load(paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/scenario_output_dataframes/scenario_output_","2020-11-11",".RData"))

# 2b) grab whale data
x.whale <-read_rds(path_whales)

# 2c) Load and prep grid cell - area key
load(path_Grid_5km_landerased)
area.key <- grid.5km.lno %>% 
  st_drop_geometry() %>% 
  select(GRID5KM_ID, area_km_lno) %>% 
  distinct()

### 2d) grab fishing metrics range to make sure normalizations are conducted properly (deals with normalizing within/across years and regions issue)
CA_fishing_metrics_range_2009_2019 <- read_rds(here:: here(
  "grid-prep",
  "CA_fishing_metrics_range_2009_2019.rds")
)

### 2e) Calculate and summarize risk
source(here:: here(
"tradeoffs",
"Management scenarios",
"Mgmt_scenarios_risk.R")
)

# will need to re-run all of the above and below for sm and lg vessels

start.time <- Sys.time()

risk_out_list <- lapply(1:nrow(scenario_table_all_trim), function(i, scenario_table_input) { # for testing. nrow(scenario_table[1:3,])
  print(paste("Summarizing risk for Scenario", i))
  #browser()
  
  risk_out <- risk_mgmt(
    x = scenario.output.list[[i]], 
    x.col = Num_DCRB_VMS_pings, 
    y = x.whale,
    risk.unit = "dens", 
    area.key = area.key,
    scale.list = CA_fishing_metrics_range_2009_2019, 
    ym.min = "2009_11", 
    ym.max = "2019_07"
  )
}, scenario_table_input = scenario_table_all_trim
)

Sys.time() - start.time
# Time difference of 19 secs

### save status quo scenario as its own df ###
#scenario_table_all_trim$scenario_df_name # use scenario_number == sq, which is 1

glimpse(risk_out_list[[1]])
risk_5km_yr_mth_sq_all <- risk_out_list[[1]]

# JS. update directory as needed
write_rds(risk_5km_yr_mth_sq_all, paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/scenario_output_dataframes/risk_5km_yr_mth_sq_all_",today(),".rds"))

# 2f) summarize risk by region

start.time <- Sys.time()
risk_out_summ_list <- lapply(1:nrow(scenario_table_all_trim), function(i, scenario_table_input) { # for testing. nrow(scenario_table[1:3,])
  print(paste("Summarizing risk for Scenario", i))
  #browser()
  
  risk_out_summ <- risk_mgmt_summ(
    x = risk_out_list[[i]], 
    summary.level = "Region"
  )
}, scenario_table_input = scenario_table_all_trim
)

Sys.time() - start.time
#Time difference of 5 secs

glimpse(risk_out_summ_list[[1]])

# JS. update directory as needed
save.image(paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/scenario_output_dataframes/scenario_output_risk_",today(),".RData"))

```

# 3. MAKE DATA FRAMES

MAKE DF'S FOR TIME SERIES OF RISK, REVENUE, AND LANDINGS (annual values)
+ status quo as separate df, all scenarios in one df, main text and supplement df's
+ repeat for sm vessels [ not yet coded ]

## Make annual and tradeoff df's, all scenarios.
```{r make_dfs1, echo=FALSE}

# note this chunk was adapted from scenario_analysis_all_vessels.R

### 1) make annual and tradeoff df's.

# 1a) # if needed, load data
# JS. update directory as needed
# load(paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/scenario_output_dataframes/scenario_output_risk_","2020-11-11",".RData"))

# 1b) make data frames
# could subset or map to region for regional summaries here
source(here::here(
"tradeoffs",
"Management scenarios",
"make_tradeoff_dataframes_function.R")
)

# note that this function writes rds files specific to JS directories (sorry!)
# also note that write_rds should be modified if running analysis for small or large vessels (~lines 119, 224)
# also also note that if sq scenario name changes  objects need to be redefined in the function (sorry again!)

start.time <- Sys.time()
tradeoff_df_function(
  risk_list = risk_out_summ_list,
  scenario_names_table = scenario_table_all_trim,
  annual_statewide_df_name = "annual_statewide_df", # this ensures df is available in the globalEnv after running function
  df_tradeoff_name = "df_tradeoff" # this ensures df is available in the globalEnv after running function
  )
Sys.time() - start.time
#Time difference of 0.24 secs

# is risk actually greater for whales under some scenarios? yes.
dim(df_tradeoff)
length(which(df_tradeoff$relative_hump_risk < 0)) # 35 out of 310
length(which(df_tradeoff$relative_blwh_risk < 0)) # 50 out of 310
length(which(df_tradeoff$relative_both_risk < 0)) # 39 out of 310

# is $ or pounds actually greater for the fishery under some scenarios? yes
length(which(df_tradeoff$relative_dollars > 100)) # 3 out of 310
length(which(df_tradeoff$relative_pounds > 100)) # 6 out of 310

```

## Make subset of main text vs supplement scenarios.
```{r make_dfs2, echo=FALSE}

# note this chunk was adapted from scenario_analysis_all_vessels.R

# give scenarios pretty names, add pre_post and year columns
scenario_names_key <- read_csv(here::here(
  "tradeoffs",
  "full_analysis_samhourietal",
  "scenario_names_key.csv"
))

annual_statewide_df %<>%
  left_join(
    scenario_names_key
  ) %<>%
  mutate(
  plotting_year = as.numeric(substr(crab_year,6,9)),
  pre_post = ifelse(plotting_year >=2015 & plotting_year <2019, "2014-2018",
                    ifelse(plotting_year <2015, "2009-2014", "2018-2019")
                    )
  )

scenario_table_all_trim %<>%
  left_join(
    scenario_names_key
  )

df_tradeoff %<>%
  left_join(
    scenario_names_key
  ) %<>%
  mutate(
  plotting_year = as.numeric(substr(crab_year,6,9)),
  pre_post = ifelse(plotting_year >=2015 & plotting_year <2019, "2014-2018",
                    ifelse(plotting_year <2015, "2009-2014", "2018-2019")
                    )
  )

# join tradeoff df to annual df to include relative changes
annual_statewide_df %<>%
  left_join(df_tradeoff)

# 1a) Subset to focal scenarios for main text

annual_statewide_df_focal_scenarios <- annual_statewide_df %>%
  filter(!grepl('alt', scenario_number))

# JS. update directory as needed
write_rds(annual_statewide_df_focal_scenarios, paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/annual_statewide_df_focal_scenarios_",today(),".rds"))

scenario_table_focal_scenarios <- scenario_table_all_trim %>%
  filter(!grepl('alt', scenario_number))

# JS. update directory as needed
write_rds(scenario_table_focal_scenarios, here::here(
  "tradeoffs",
  "Management scenarios",
  paste0("scenario_table_focal_scenarios_",today(),".rds"))
)

df_tradeoff_focal_scenarios <- df_tradeoff  %>%
  filter(!grepl('alt', scenario_number))

# JS. update directory as needed
write_rds(df_tradeoff_focal_scenarios, paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/df_tradeoff_focal_scenarios_",today(),".rds"))

# 1b) Subset to focal scenarios for supplement

annual_statewide_df_supplement <- annual_statewide_df %>%
  filter(grepl('alt', scenario_number) | grepl('sq', scenario_number))

# JS. update directory as needed
write_rds(annual_statewide_df_supplement, paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/annual_statewide_df_supplement_",today(),".rds"))

scenario_table_supplement <- scenario_table_all_trim %>%
  filter(grepl('alt', scenario_number) | grepl('sq', scenario_number))

# JS. update directory as needed
write_rds(scenario_table_supplement, here::here(
  "tradeoffs",
  "Management scenarios",
  paste0("scenario_table_supplement_",today(),".rds"))
)

df_tradeoff_supplement <- df_tradeoff  %>%
  filter(grepl('alt', scenario_number) | grepl('sq', scenario_number))

# JS. update directory as needed
write_rds(df_tradeoff_supplement, paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/df_tradeoff_supplement_",today(),".rds"))

# 1c) Subset to status quo scenario only

annual_statewide_df_sq <- annual_statewide_df %>%
  filter(grepl('sq', scenario_number))

# JS. update directory as needed
write_rds(annual_statewide_df_sq, paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/annual_statewide_df_sq_",today(),".rds"))

scenario_table_sq <- scenario_table_all_trim %>%
  filter(grepl('sq', scenario_number))

# JS. update directory as needed
write_rds(scenario_table_sq, here::here(
  "tradeoffs",
  "Management scenarios",
  paste0("scenario_table_sq_",today(),".rds"))
)

df_tradeoff_sq <- df_tradeoff  %>%
  filter(grepl('sq', scenario_number))

# JS. update directory as needed
write_rds(df_tradeoff_sq, paste0("/Users/jameal.samhouri/Documents/RAIMBOW/Processed Data/Samhouri et al. whales risk/Output_Data/df_tradeoff_sq_",today(),".rds"))

```

# 4. CALCULATE SCENARIO RANKS

CALCULATE SCENARIO RANKS
+ one df by year, one by period
+ repeat for statewide only and cenCA only scenarios
+ also make scale_compare df by period
+ ranks based on hump risk, blwh risk, DCRB $, DCRB lbs, cost effectiveness for humps, cost effectiveness for blues

## Calculate scenario ranks each year and each period, all scenarios
```{r rank_scenarios1, echo=FALSE}

```

## Calculate scenario ranks each year and each period, statewide focal scenarios
```{r rank_scenarios2, echo=FALSE}

```

## Calculate scenario ranks each year and each period, cenCA only focal scenarios
```{r rank_scenarios3, echo=FALSE}

```

## Make df's to compare scales of management in different periods
```{r rank_scenarios, echo=FALSE}

### compare risk based on scale of mgmt scenario

# 1a) focal scenarios for main text
scale_compare_focal_scenarios <- annual_statewide_df_focal_scenarios %>%
  filter(!stringr::str_detect(pretty_scenario_names, 'Status Quo|BIA|, Early')) %>%
  mutate(
  
    scale = ifelse(delay.region == "All" | closure.region == "All" | reduction.after.region == "All",
                 "Statewide",
                 ifelse(delay.region == "CenCA" | closure.region == "CenCA" | reduction.after.region == "CenCA",
                        "Central California Only", NA)),
    
  scenario_type = ifelse(stringr::str_detect(pretty_scenario_names, 'Depth Restriction') & stringr::str_detect(pretty_scenario_names, 'Effort Reduction'), "Depth and Gear Restrictions",
                         ifelse(stringr::str_detect(pretty_scenario_names, 'Depth Restriction') & !stringr::str_detect(pretty_scenario_names, 'Effort Reduction'), "Depth Restriction",
                                ifelse(!stringr::str_detect(pretty_scenario_names, 'Depth Restriction') & stringr::str_detect(pretty_scenario_names, 'Effort Reduction'), "Gear Restriction",                                   
                                       ifelse(stringr::str_detect(pretty_scenario_names, 'Early Closure'), "Early Closure", 
                                              ifelse(stringr::str_detect(pretty_scenario_names, 'Delay'), "Delayed Opening", NA)
                                              )
                                       )
                                )
                         )
  ) %>%
  group_by(pretty_scenario_names, pre_post, scale, scenario_type) %>%
  summarise(
    mean_n_risk_blue = mean(n_risk_blue),
    mean_n_risk_humpback = mean(n_risk_humpback),
    mean_n_risk_both = mean(n_risk_both),
    mean_DCRB_rev = mean(DCRB_rev),
    
    se_n_risk_blue = sd(n_risk_blue)/sqrt(n()),
    se_n_risk_humpback = sd(n_risk_humpback)/sqrt(n()),
    se_n_risk_both = sd(n_risk_both)/sqrt(n()),
    se_DCRB_rev = sd(DCRB_rev)/sqrt(n()),
    
    mean_relative_hump_risk_n = mean(relative_hump_risk_n),
    mean_relative_blwh_risk_n = mean(relative_blwh_risk_n),
    mean_relative_both_risk_n = mean(relative_both_risk_n),
    mean_relative_dollars = mean(relative_dollars),
    
    se_relative_hump_risk_n = sd(relative_hump_risk_n)/sqrt(n()),
    se_relative_blwh_risk_n = sd(relative_blwh_risk_n)/sqrt(n()),
    se_relative_both_risk_n = sd(relative_both_risk_n)/sqrt(n()),
    se_relative_dollars = sd(relative_dollars)/sqrt(n()),
    
    .groups = "drop"
  ) 
  
glimpse(scale_compare_focal_scenarios)
write_rds(scale_compare_focal_scenarios, 
          here::here(
            "tradeoffs",
            "Management scenarios",
            "scale_compare_all_vessels.rds")
          )


# 1b) focal scenarios for supplement
scale_compare_supplement <- annual_statewide_df_supplement %>%
  filter(!stringr::str_detect(pretty_scenario_names, 'Status Quo|BIA|, Early')) %>%
  mutate(
  
    scale = ifelse(delay.region == "All" | closure.region == "All" | reduction.after.region == "All",
                 "Statewide",
                 ifelse(delay.region == "CenCA" | closure.region == "CenCA" | reduction.after.region == "CenCA",
                        "Central California Only", NA)),
    
  scenario_type = ifelse(stringr::str_detect(pretty_scenario_names, 'Depth Restriction') & stringr::str_detect(pretty_scenario_names, 'Effort Reduction'), "Depth and Gear Restrictions",
                         ifelse(stringr::str_detect(pretty_scenario_names, 'Depth Restriction') & !stringr::str_detect(pretty_scenario_names, 'Effort Reduction'), "Depth Restriction",
                                ifelse(!stringr::str_detect(pretty_scenario_names, 'Depth Restriction') & stringr::str_detect(pretty_scenario_names, 'Effort Reduction'), "Gear Restriction",                                   
                                       ifelse(stringr::str_detect(pretty_scenario_names, 'Early Closure'), "Early Closure", 
                                              ifelse(stringr::str_detect(pretty_scenario_names, 'Delay'), "Delayed Opening", NA)
                                              )
                                       )
                                )
                         )
  ) %>%
  group_by(pretty_scenario_names, pre_post, scale, scenario_type) %>%
  summarise(
    mean_n_risk_blue = mean(n_risk_blue),
    mean_n_risk_humpback = mean(n_risk_humpback),
    mean_n_risk_both = mean(n_risk_both),
    mean_DCRB_rev = mean(DCRB_rev),
    
    se_n_risk_blue = sd(n_risk_blue)/sqrt(n()),
    se_n_risk_humpback = sd(n_risk_humpback)/sqrt(n()),
    se_n_risk_both = sd(n_risk_both)/sqrt(n()),
    se_DCRB_rev = sd(DCRB_rev)/sqrt(n()),
    
    mean_relative_hump_risk_n = mean(relative_hump_risk_n),
    mean_relative_blwh_risk_n = mean(relative_blwh_risk_n),
    mean_relative_both_risk_n = mean(relative_both_risk_n),
    mean_relative_dollars = mean(relative_dollars),
    
    se_relative_hump_risk_n = sd(relative_hump_risk_n)/sqrt(n()),
    se_relative_blwh_risk_n = sd(relative_blwh_risk_n)/sqrt(n()),
    se_relative_both_risk_n = sd(relative_both_risk_n)/sqrt(n()),
    se_relative_dollars = sd(relative_dollars)/sqrt(n()),
    
    .groups = "drop"
  ) 
  
glimpse(scale_compare_supplement)
write_rds(scale_compare_supplement, 
          here::here(
            "tradeoffs",
            "Management scenarios",
            "scale_compare_all_vessels_supplement.rds")
          )


```

# remember that i want to:
# 5. CALCULATE CHANGES IN RISK AND REVENUE BY PERIOD AND SCENARIO
+ repeat for statewide only and cenCA only scenarios
+ % change in each scenario's impact on risk and revenue between 2009-14 and 2014-18 periods

# 6. QUERY ENTANGLEMENT DATA

## Entanglements by period and species
```{r entanglements, echo=FALSE}

entanglement_df_annual_complete <- read_csv(path_entanglement_file2)

entanglement_df_annual_complete %>% 
  mutate(
    period = case_when(
      Year == 2009 | Year == 2010 | Year == 2011 | Year == 2012 | Year == 2013 ~ "pre",
      Year == 2014 | Year == 2015 | Year == 2016 | Year == 2017 | Year == 2018 ~ "mhw",
      Year == 2019 ~ "post",
      TRUE ~ "OTHER"
    )
  ) %>%
  filter( Year >= 2009) %>%
  group_by(period, species) %>%
  summarise(
    total = sum(count)
  ) %>%
  arrange(
    species,
    factor(period, levels = c("pre", "mhw", "post"))
  ) %>%
  knitr::kable()

```

## Entanglements by period, all species combined
```{r entanglements2, echo=FALSE}

entanglement_df_annual_complete <- read_csv(path_entanglement_file2)

entanglement_df_annual_complete %>% 
  mutate(
    period = case_when(
      Year == 2009 | Year == 2010 | Year == 2011 | Year == 2012 | Year == 2013 ~ "pre",
      Year == 2014 | Year == 2015 | Year == 2016 | Year == 2017 | Year == 2018 ~ "mhw",
      Year == 2019 ~ "post",
      TRUE ~ "OTHER"
    )
  ) %>%
  filter( Year >= 2009) %>%
  group_by(period) %>%
  summarise(
    total = sum(count)
  ) %>%
  arrange(
    factor(period, levels = c("pre", "mhw", "post"))
  ) %>%
  knitr::kable()

```

# 7. QUERY FISHING DATA

```{r fishing, include=FALSE}


# most of this code originally from query_fishing_data.R
# this takes a few min to read in
dcrb_vms_tix_analysis <- read_rds(path_dcrb_vms_tix_analysis)
glimpse(dcrb_vms_tix_analysis)

# check years included
unique(dcrb_vms_tix_analysis$year)

#####################################################
# filter the data using the control variables below
# years <- seq(2009,2019,1)

state_agency_code <- "C"
#state <- "CA"
target_rev <- "DCRB"
target_lbs <- "DCRB"
region_north <- c(1040, 1041, 1042)
vessel_size_category_break <- 40
winter_months <- c("November", "December", "January", "February", "March")
crab_months <- c(1:7,11:12)
removal_types <- c("COMMERCIAL (NON-EFP)", "COMMERCIAL(DIRECT SALES)", "UNKNOWN")
max_speed <- 4.11556
min_speed <- 0

#ports <- c("CCA", "ERA", "BGA","BDA", "SFA", "MRA", "MNA")
#region_south <- c(1035, 1036, 1037, 1038)
#####################################################

#####################################################

# subset the data based on above queries. CA only
dcrb_ca_vms_tix_analysis <- dcrb_vms_tix_analysis %>%
  filter(agency_code == state_agency_code) %>%
  #filter(agency_code == state_agency_code & STATE == state) %>%
  filter(TARGET_rev == target_rev | TARGET_lbs == target_lbs) %>%
  filter(removal_type_name %in% removal_types) %>%
  filter(CA_OFFSHOR != -999) %>%
  filter(DEPTH_CATM == "0-100m" | DEPTH_CATM == "100-150m") %>%
  #filter(NGDC_M <= 0 & NGDC_M >= -12000) %>% # considered adding 052220. also see "evaluate fishing depths.R". probably unnecessary because NGDC_M refers to centroid depth and we can match depths by 5km grid cell later
  filter(avg_speed_recalc <= max_speed & avg_speed_recalc >= min_speed) %>%
  #filter(is.na(in_port) == TRUE) %>% # only removes ~4000 records
  #filter(port_group_code %in% ports) %>%
  mutate(#GRID5KM_ID = as.character(GRID5KM_ID),
    Region = ifelse(CA_OFFSHOR %in% region_north,
                    "NorCA","CenCA"),
    BIA_mn_noNAs = ifelse(is.na(BIA_mn)==TRUE,0,BIA_mn),
    BIA_bm_noNAs = ifelse(is.na(BIA_bm)==TRUE,0,BIA_bm),
    #year = lubridate::year(westcoastdate_notime), # removed because it is included with the vessel_lengths step
    year_month = paste0(lubridate::year(westcoastdate_notime),"_", substr(lubridate::ymd(westcoastdate_notime),6,7)), # substr() ensures month is a 2 digit value
    month = lubridate::month(westcoastdate_notime, label=TRUE, abbr = FALSE),
    month_as_numeric = month(westcoastdate_notime),
    week_of_year = week(westcoastdate_notime),
    day_of_year = yday(westcoastdate_notime),
    season = as.character(ifelse(month %in% winter_months, "Winter", "Spring-Summer")),
    crab_year = ifelse(
      month_as_numeric >= 11, paste0(year,"_",1+year), paste0(year - 1,"_",year)
    ),
    Vessel_Size = as.character(ifelse(FINAL_LENGTH >= vessel_size_category_break, paste0(">=",vessel_size_category_break, " ft"),paste0("<",vessel_size_category_break, " ft"))),
    BIA_bm_or_mn = ifelse(BIA_bm_noNAs !=0 | BIA_mn_noNAs != 0, "Inside BIA","Outside BIA")#,
  ) %>%
  filter(westcoastdate_notime >= as.Date("2009-11-01") & westcoastdate_notime <= as.Date("2019-08-01")) %>%
  filter(month_as_numeric %in% crab_months) %>%
  dplyr::select(
    Rec_ID, VMS_RECNO, drvid, Vessel_Size,
    westcoastdate_notime, year, crab_year, year_month, month, month_as_numeric, week_of_year, day_of_year, season,
    GRID5KM_ID, BAND_25KM, BAND_50KM, CA_OFFSHOR, Region, BIA_mn_noNAs, BIA_bm_noNAs, BIA_bm_or_mn, pacfin_port_code, port_group_code, DEPTH_CATM, NGDC_M,
    TARGET_lbs, TARGET_rev, DCRB_lbs, DCRB_revenue
  )

#glimpse(dcrb_ca_vms_tix_analysis)
```

## All 10 Years
Number unique vessels  tix, geolocations, and total revenue and landings
(VMS-tracked only)

```{r fishing2, echo=FALSE}
# number of unique vessels
total_num_vessels <- length(unique(dcrb_ca_vms_tix_analysis$drvid)) #283

# number of unique tix
total_num_tix <- length(unique(dcrb_ca_vms_tix_analysis$Rec_ID)) #16182

# number of unique geolocations
total_num_locations <- length(unique(dcrb_ca_vms_tix_analysis$VMS_RECNO)) #369688

# total revenue
total_rev <- sum(dcrb_ca_vms_tix_analysis$DCRB_revenue) #6563123120

# total landings
total_landings <- sum(dcrb_ca_vms_tix_analysis$DCRB_lbs) #2234063912


data.frame(total_num_vessels,
           total_num_tix,
           total_num_locations,
           total_rev,
           total_landings) %>%
  knitr::kable()


```

## By period

Number unique vessels  tix, geolocations, and total revenue and landings by period
(VMS-tracked only)
```{r fishing3, echo=FALSE}

# summed revenue of VMS vessels 2009-14 vs 2014-18
#unique(dcrb_ca_vms_tix_analysis$crab_year)

period_summaries <- dcrb_ca_vms_tix_analysis %>%
  mutate(
    period = case_when(
      crab_year %in% c("2009_2010","2010_2011","2011_2012","2012_2013","2013_2014") ~ "pre",
      crab_year %in% c("2014_2015","2016_2017","2015_2016","2017_2018") ~ "MHW",
      TRUE ~ "post"
    ) 
  ) %>%
  group_by(period) %>%
  summarise(
    num_vessels = length(unique(drvid)),
    num_tix = length(unique(Rec_ID)),
    num_locations = length(unique(VMS_RECNO)),
    sum_DCRB_rev = sum(DCRB_revenue),
    sum_DCRB_lbs = sum(DCRB_lbs)
    
  ) %>%
  mutate(
    annual_rev = case_when(
      period == "MHW" ~ sum_DCRB_rev/4,
      period == "pre" ~ sum_DCRB_rev/5,
      period == "post" ~ sum_DCRB_rev/1
      #TRUE ~ "ERROR"
    )
  ) %>%
    arrange(
    factor(period, levels = c("pre", "MHW", "post"))
           ) 

annual_percent_rev_change_MHW_v_pre <- 100 * ( period_summaries$annual_rev[which(period_summaries$period == "MHW")] - period_summaries$annual_rev[which(period_summaries$period == "pre")] ) / period_summaries$annual_rev[which(period_summaries$period == "pre")]

period_summaries %>%
  knitr::kable()

print("annual_percent_rev_change_MHW_v_pre")
annual_percent_rev_change_MHW_v_pre


```

## By period and region

Number unique vessels  tix, geolocations, and total revenue and landings by period and region
(VMS-tracked only)
```{r fishing4, echo=FALSE}

# summed revenue of VMS vessels 2009-14 vs 2014-18
#unique(dcrb_ca_vms_tix_analysis$crab_year)

period_region_summaries <- dcrb_ca_vms_tix_analysis %>%
  mutate(
    period = case_when(
      crab_year %in% c("2009_2010","2010_2011","2011_2012","2012_2013","2013_2014") ~ "pre",
      crab_year %in% c("2014_2015","2016_2017","2015_2016","2017_2018") ~ "MHW",
      TRUE ~ "post"
    ) 
  ) %>%
  group_by(period, Region) %>%
  summarise(
    num_vessels = length(unique(drvid)),
    num_tix = length(unique(Rec_ID)),
    num_locations = length(unique(VMS_RECNO)),
    sum_DCRB_rev = sum(DCRB_revenue),
    sum_DCRB_lbs = sum(DCRB_lbs)
    
  ) %>%
  #group_by(Region) %>%
  mutate(
    annual_rev = case_when(
      period == "MHW" ~ sum_DCRB_rev/4,
      period == "pre" ~ sum_DCRB_rev/5,
      period == "post" ~ sum_DCRB_rev/1
      #TRUE ~ "ERROR"
    )
  ) %>%
    arrange(
      Region,
    factor(period, levels = c("pre", "MHW", "post"))
           ) 

annual_percent_rev_change_MHW_v_pre_region <- 100 * ( period_region_summaries$annual_rev[which(period_region_summaries$period == "MHW")] - period_region_summaries$annual_rev[which(period_region_summaries$period == "pre")] ) / period_region_summaries$annual_rev[which(period_region_summaries$period == "pre")]

period_region_summaries %>%
  knitr::kable()

print("annual_percent_rev_change_MHW_v_pre_region")
annual_percent_rev_change_MHW_v_pre_region


```

Total revenue and landings by crab year and period for all fish tix
(not yet analyzed)

# 8. QUERY WHALE MODEL OUTPUTS
+ predicted occurrence/density by period, statewide and by region
