---
title: "Pre-processing OR logbook data"
author: "Leena"
date: "11/08/2021"
output: html_document
---

# Pre-processing OR logbook data so that the code used for WDFW logbook analysis and mapping can be used for OR as well
# The code here are based on code files received from WDFW:
# 'Read and prep crab logbook data_2020-08-28.Rmd' and
# 'Create-and-save-GIS-sf_and_gdb.Rmd'

```{r}
library(tidyverse)
library(here)
library(data.table)
library(stringr)
library(magrittr)
library(lubridate)
library(sf)

```
# Read in data

In the logbook data folder received from ODFW, there was a file Samhouri_CrabLogData_sent030620.xlsx
This file has logbook data covering seasons from 2007-2008 to 2017-2018
and it was saved as csv prior to loading into R

```{r}
logs <- read_csv(here::here('wdfw','data','OR','Samhouri_CrabLogData_sent030620.csv'),col_types = 'cdccddddddddddccc')
#fields such as vessel ID is often a  number, but want to read it in as a character

#rename some variables to match WDFW data
logs %<>% 
  rename(season=Season, Vessel=VessID, SetDate=Date, Depth_fth=Depth, PotsFished=Pots, adj_lbs=AdjLbs, adj_val=AdjVal, LATBEG=BegLat, LONGBEG=Beglon, LATEND=EndLat, LONGEND=EndLon)

glimpse(logs)
#note that not all columns exist in both WA and OR logbook data
```
# Format SetDate column
```{r}
logs %<>%
  mutate(SetDate=as.Date(SetDate,"%d-%b-%y"))

```
# Add an ID

Each row in the OR logbook data should reflect an individual string-line of pots
First add an arbitrary ID value starting from 1 for the entire data set
Then create a 'SetID' that incorporates the season in question, and the ID number
The value of the SetID doesn't matter that much, but we want to make sure each string-line has a unique ID

```{r}
logs$IDsets <- seq.int(nrow(logs))

logs$SetID <- paste0(logs$season, "_", logs$IDsets)

```
#The following is from 'Create-and-save-GIS-sf_and_gdb.Rmd' from WDFW
this Rmd was ran up to line 58 (in the original Rmd from WDFW) for both WA and OR logbook data

# Stack Coordinates
the code is from WDFW and uses data.table - convert to data.table first to run the code
```{r}
setDT(logs) 

log_coords <- rbind(logs[, .(lat = LATBEG,
               lon = LONGBEG,
               coord_type = "begin"), keyby = SetID],
      logs[, .(lat = LATEND,
               lon = LONGEND,
               coord_type = "end"), keyby = SetID])

log_coords <- log_coords[complete.cases(log_coords), ]

log_coords$lon <- log_coords$lon*(-1)
```
# Rejoin Attributes

This is an inner join using standard data.table syntax (i.e. select rows of logs, filtering on SetIDs that appear in log_coords, and nomatch=NULL tells it to drop rows with no matches.)
```{r}
logs_sf_pts <- logs[log_coords, on = "SetID", nomatch = NULL]
```
## we only ran 'Create-and-save-GIS-sf_and_gdb.Rmd'on WA logs data up to this point

#Export as csv
```{r}
fwrite(logs_sf_pts, paste0(here::here(), 
                    "/wdfw/", "/data/", "/OR/", 
                    "ODFW-Dcrab-logbooks-compiled_stackcoords_2007-2018", 
                    "_", 
                    Sys.Date(), ".csv"))

#after exporting order data in excel
```
# OPTIONAL
remove any records for whom the spatial information is unreasonable (variable `SpatialFlag==T`)??
Alternatively, leave in and they should get removed in script 1 when removing points too deep or on land

```{r}

```
# COuple additional check from 'Read and prep crab logbook data_2020-08-28.Rmd'
## Check for errors

There should only be two years within a season. 
2015-2016 and 2017-2018 only have data in the latter years - Fits because season opening data was only in January

First, get the season start and ending years. Test to see if the Set Date year matches one of those years.

The OR logs did not come with landing dates, but they could probably be retrieved using FishTicket numbers
```{r}
#logs_sf_pts[, .(year = unique(year(SetDate))), 
#     keyby = season][, dcast(.SD, season ~ year)]

#logs_sf_pts[, c("start_year", "end_year") := tstrsplit(season, "-")
#     ][, `:=`(start_year = as.numeric(start_year), 
#              end_year = as.numeric(end_year))]

#check_setdate <- logs_sf_pts[year(SetDate) != start_year &
#       year(SetDate) != end_year, ]

#check_setdate #empty
```
The WA logbook coding from WDFW added start dates into the df
But these were not used in analysis and mapping

```{r}
#From data.table to data.frame
setDF(logs_sf_pts)
#logs_raw <- read_csv(here('wdfw', 'data','OR', 'ODFW-Dcrab-logbooks-compiled_stackcoords_2007-2018_2021-08-11.csv'),col_types = 'cdccddddddddddcccdcddc') #no parsing errors with these col_types


library(fuzzyjoin)
#OR permits: 
#in folder from ODFW had OregonCrabPermitData2007-2019.xlsx, saved as csv 
# Read in and join license & pot limit info
OR_pot_limit_info_raw <- read_csv(here::here('wdfw', 'data', 'OR', 'OregonCrabPermitData2007-2019.csv'))

OR_pot_limit_info <- OR_pot_limit_info_raw %>% 
  rename(Vessel = Docnum,
         PermitNumber = Number)

OR_pot_limit_info %<>%
  mutate(Begindate=as.Date(Begindate,"%m/%d/%Y"),
         Enddate=as.Date(Enddate,"%m/%d/%Y"))

OR_pot_limit_info %>% distinct(Potlimit) # 500, 300, 200
#OR permits - a permit can change from vessel to vessel sometimes 
#but does the pot limit for a given permit number stay the same?
test <- OR_pot_limit_info %>%                              
  group_by(PermitNumber) %>%
  summarise(count = n_distinct(Potlimit))
# Yes, except for 2 instances: Permit Numbers 96125 and 96262 have 2 unique pot limit values
cases <- OR_pot_limit_info %>% 
  filter(PermitNumber == 96125 | PermitNumber == 96262)
#96125: for 12 years pot limit is 300, but in 2014 it is 500 - assume mistake for now
#96262: for 12 years pot limit is 300, but in 2008 it is 200 - assume mistake for now, also possibly outside years of interest anyway
OR_pot_limit_info %<>%
  mutate(Potlimit = ifelse(PermitNumber == 96125 | PermitNumber == 96262, 300, Potlimit))

OR_pot_limit_info_v2 <- OR_pot_limit_info %>% 
  filter(Year >= 2013) %>% 
  select(PermitNumber, Vessel, Begindate, Enddate, Potlimit)

# joining permit data
# doing it 'manually' for now while figuring out how to code it more efficiently
# for some reason joining didn't work if read in the ODFW-Dcrab-logbooks-compiled_stackcoords_2007-2018.csv that was saved earlier, but worked on the logs_sf_pts dataframe (which was saved as ODFW-Dcrab-logbooks-compiled_stackcoords_2007-2018.csv)

#2013-2014 season - 12mins to run with permit data filtered to post 2013
ODFW_Dcrab_logbooks_20132014 <- logs_sf_pts %>% 
  filter(season=='2013-2014')
tm <- proc.time()
ODFW_Dcrab_logbooks_20132014_joined <- fuzzy_left_join(
  ODFW_Dcrab_logbooks_20132014, OR_pot_limit_info_v2,
  by = c(
    "Vessel" = "Vessel",
    "SetDate" = "Begindate",
    "SetDate" = "Enddate"
  ),
  match_fun = list(`==`, `>=`, `<=`)
)
proc.time()-tm
write_csv(ODFW_Dcrab_logbooks_20132014_joined,here::here('wdfw', 'data', 'OR', "ODFW-Dcrab-logbooks-compiled_stackcoords_license_2013-2014.csv"))

#2014-2015 season - 12mins to run with permit data filtered to post 2013
ODFW_Dcrab_logbooks_20142015 <- logs_sf_pts %>% 
  filter(season=='2014-2015')
tm <- proc.time()
ODFW_Dcrab_logbooks_20142015_joined <- fuzzy_left_join(
  ODFW_Dcrab_logbooks_20142015, OR_pot_limit_info_v2,
  by = c(
    "Vessel" = "Vessel",
    "SetDate" = "Begindate",
    "SetDate" = "Enddate"
  ),
  match_fun = list(`==`, `>=`, `<=`)
)
proc.time()-tm
write_csv(ODFW_Dcrab_logbooks_20142015_joined,here::here('wdfw', 'data', 'OR', "ODFW-Dcrab-logbooks-compiled_stackcoords_license_2014-2015.csv"))


#2015-2016 season - 15mins to run with permit data filtered to post 2013
ODFW_Dcrab_logbooks_20152016 <- logs_sf_pts %>% 
  filter(season=='2015-2016')
tm <- proc.time()
ODFW_Dcrab_logbooks_20152016_joined <- fuzzy_left_join(
  ODFW_Dcrab_logbooks_20152016, OR_pot_limit_info_v2,
  by = c(
    "Vessel" = "Vessel",
    "SetDate" = "Begindate",
    "SetDate" = "Enddate"
  ),
  match_fun = list(`==`, `>=`, `<=`)
)
proc.time()-tm
write_csv(ODFW_Dcrab_logbooks_20152016_joined,here::here('wdfw', 'data', 'OR', "ODFW-Dcrab-logbooks-compiled_stackcoords_license_2015-2016.csv"))


#2016-2017 season - 14mins to run with permit data filtered to post 2013
ODFW_Dcrab_logbooks_20162017 <- logs_sf_pts %>% 
  filter(season=='2016-2017')
tm <- proc.time()
ODFW_Dcrab_logbooks_20162017_joined <- fuzzy_left_join(
  ODFW_Dcrab_logbooks_20162017, OR_pot_limit_info_v2,
  by = c(
    "Vessel" = "Vessel",
    "SetDate" = "Begindate",
    "SetDate" = "Enddate"
  ),
  match_fun = list(`==`, `>=`, `<=`)
)
proc.time()-tm
write_csv(ODFW_Dcrab_logbooks_20162017_joined,here::here('wdfw', 'data', 'OR', "ODFW-Dcrab-logbooks-compiled_stackcoords_license_2016-2017.csv"))


#2017-2018 season - 14mins to run with permit data filtered to post 2013
ODFW_Dcrab_logbooks_20172018 <- logs_sf_pts %>% 
  filter(season=='2017-2018')
tm <- proc.time()
ODFW_Dcrab_logbooks_20172018_joined <- fuzzy_left_join(
  ODFW_Dcrab_logbooks_20172018, OR_pot_limit_info_v2,
  by = c(
    "Vessel" = "Vessel",
    "SetDate" = "Begindate",
    "SetDate" = "Enddate"
  ),
  match_fun = list(`==`, `>=`, `<=`)
)
proc.time()-tm
write_csv(ODFW_Dcrab_logbooks_20172018_joined,here::here('wdfw', 'data', 'OR', "ODFW-Dcrab-logbooks-compiled_stackcoords_license_2017-2018.csv"))


###################
#OR permits: 
#in folder from ODFW had OregonCrabPermitData2007-2019.xlsx, saved as csv 
# Read in and join license & pot limit info
OR_pot_limit_info_raw <- read_csv(here::here('wdfw', 'data', 'OR', 'OregonCrabPermitData2007-2019.csv'))

OR_pot_limit_info <- OR_pot_limit_info_raw %>% 
  rename(Vessel = Docnum,
         PermitNumber = Number)

OR_pot_limit_info %<>%
  mutate(Begindate=as.Date(Begindate,"%m/%d/%Y"),
         Enddate=as.Date(Enddate,"%m/%d/%Y"))


OR_pot_limit_info %>% distinct(Potlimit) # 500, 300, 200
#OR permits - a permit can change from vessel to vessel sometimes 
#but does the pot limit for a given permit number stay the same?
test <- OR_pot_limit_info %>%                              
  group_by(PermitNumber) %>%
  summarise(count = n_distinct(Potlimit))
# Yes, except for 2 instances: Permit Numbers 96125 and 96262 have 2 unique pot limit values
cases <- OR_pot_limit_info %>% 
  filter(PermitNumber == 96125 | PermitNumber == 96262)
#96125: for 12 years pot limit is 300, but in 2014 it is 500 - assume mistake for now
#96262: for 12 years pot limit is 300, but in 2008 it is 200 - assume mistake for now, also possibly outside yers of interest anyway
OR_pot_limit_info %<>%
  mutate(Potlimit = ifelse(PermitNumber == 96125 | PermitNumber == 96262, 300, Potlimit))

OR_pot_limit_info_v2 <- OR_pot_limit_info %>% 
  filter(Year >= 2013) %>% 
  select(PermitNumber, Vessel, Begindate, Enddate, Potlimit)

#vector size too large, might need to try running in subsets
traps_g_joined <- fuzzy_left_join(
  traps_g_20132014, OR_pot_limit_info_v2,
  by = c(
    "Vessel" = "Vessel",
    "SetDate" = "Begindate",
    "SetDate" = "Enddate"
  ),
  match_fun = list(`==`, `>=`, `<=`)
) #%>%
#select(column_name, category = category.x, column_name, column_name)

dat_list = split(df, df$season)
dat_list

join_log_permit = function(data) {
  fuzzy_left_join(
    data, OR_pot_limit_info_v2,
    by = c(
      "Vessel" = "Vessel",
      "SetDate" = "Begindate",
      "SetDate" = "Enddate"
    ),
    match_fun = list(`==`, `>=`, `<=`)
  )
}
join_log_permit(data = df)
map_dfr(dat_list, join_log_permit, .season = "season")

##################


logs_raw <- read_csv(here('wdfw', 'data','OR', 'ODFW-Dcrab-logbooks-compiled_stackcoords_2007-2018_2021-08-11.csv'),col_types = 'cdccddddddddddcccdcddc') #no parsing errors with these col_types

logs  <-  logs_raw %>% 
  mutate(SetDate=as.Date(SetDate,"%d/%m/%Y"))

logs2013_2018 <- logs %>% 
  filter(season %in% c('2013-2014','2014-2015','2015-2016','2016-2017','2017-2018')) 

df <- logs2013_2018

df %<>%
  dplyr::select(season,Vessel,SetID,lat,lon,PotsFished,SetDate,coord_type) %>%  #License, 
  distinct() 



ids <- unique(df$season)
#df_list = list()
for (i in 1:length(ids)) {
  
 df_x  <- df %>% 
   filter(season == ids[i])
  
 p <- fuzzy_left_join(
  df_x, OR_pot_limit_info_v2,
  by = c(
    "Vessel" = "Vessel",
    "SetDate" = "Begindate",
    "SetDate" = "Enddate"
  ),
  match_fun = list(`==`, `>=`, `<=`)
)
   #df_list[[i]] = p
write_csv(p,here::here('wdfw', 'data', 'OR', paste0("loop_",df_list[i],".csv")))
}

#create pdf where each page is a separate plot.
pdf("Tohora2020_Number of locations per day over time.pdf")
for (i in 1:length(ids)) {
    print(df_list[[i]])
}
dev.off()

for(i in 1:length(df_list)) {                              # Head of for-loop
  write.csv2(get(df_list[i]),                              # Write CSV files to folder
             paste0("C:/Users/Joach/Desktop/My Folder/",
                    df_list[i],
                    ".csv"),
             row.names = FALSE)
}
```

